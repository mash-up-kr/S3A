# 10ì¥ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬
## 10.1 ìŠ¤í‚¤ë§ˆì˜ ê°œë…ê³¼ ìœ ìš©ì„±
- **ì¹´í”„ì¹´ì— ìŠ¤í‚¤ë§ˆê°€ ì—†ë‹¤ë©´,** ëˆ„êµ°ê°€ì˜ ì‹¤ìˆ˜ë¡œ ì •ì˜ë˜ì§€ ì•Šì€ í˜•íƒœì˜ ë°ì´í„°ë¥¼ í•´ë‹¹ í† í”½ìœ¼ë¡œ ë³´ë‚¸ë‹¤ë©´, ê·¸ì™€ ì—°ê²°ëœ ëª¨ë“  ì‹œìŠ¤í…œì´ ì˜í–¥ì„ ë°›ê²Œ ë  ê²ƒì´ê³ , ì‹¬ê°í•œ ë¬¸ì œë¥¼ ì•¼ê¸°í•  ìˆ˜ ìˆë‹¤.
- ë°ì´í„°ë¥¼ ì»¨ìŠ˜í•˜ëŠ” ì—¬ëŸ¬ ë¶€ì„œì—ê²Œ ê·¸ ë°ì´í„°ì— ëŒ€í•œ ì •í™•í•œ ì •ì˜ì™€ ì˜ë¯¸ë¥¼ ì•Œë ¤ì£¼ëŠ” ì—­í• ì„ í•˜ëŠ” ê²ƒì´ **ìŠ¤í‚¤ë§ˆ**ì´ë‹¤.
- ì¹´í”„ì¹´ì—ì„œ ìŠ¤í‚¤ë§ˆì˜ ì§„í™”ë¥¼ ì§€ì›í•˜ì—¬, ì¹´í”„ì¹´ë¥¼ ì‚¬ìš©í•˜ëŠ” ìˆ˜ì‹­~ìˆ˜ë°±ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ë“¤ì´ ë³„ë‹¤ë¥¸ ì˜í–¥ ì—†ì´ ìŠ¤í‚¤ë§ˆë¥¼ ë³€ê²½í•  ìˆ˜ ìˆë‹¤.
- ğŸ‘ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸°ì— ì•ì„œ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•˜ëŠ” ì‘ì—…ì—ëŠ” ë§ì€ ì‹œê°„ê³¼ ë…¸ë ¥ì´ ë“ ë‹¤. (í•˜ì§€ë§Œ ì´ë¥¼ ê°ìˆ˜í• ë§Œí¼ ì´ì ì´ ë§ìŒ)

<br/>

## 10.2 ì¹´í”„ì¹´ì™€ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬
### 10.2.1 ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê°œìš”

<img alt="image" width=500 src="https://github.com/mash-up-kr/S3A/assets/55437339/912c034f-d2a7-4228-b7a6-2c216fe47d1d"/>

ğŸ”¼ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ êµ¬ì„±ë„
- ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” í”„ë¡œë“€ì„œ/ì»¨ìŠˆë¨¸ì™€ ì§ì ‘ í†µì‹ í•œë‹¤.
- í”„ë¡œë“€ì„œëŠ” ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ìŠ¤í‚¤ë§ˆë¥¼ ë“±ë¡í•˜ê³ , ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” ë“±ë¡ëœ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ì¹´í”„ì¹´ì˜ ë‚´ë¶€ í† í”½ì— ì €ì¥í•œë‹¤.
- í”„ë¡œë“€ì„œëŠ” ë“±ë¡ëœ ìŠ¤í‚¤ë§ˆì˜ IDì™€ ë©”ì‹œì§€ë¥¼ ì¹´í”„ì¹´ë¡œ ì „ì†¡í•˜ê³ , ì»¨ìŠˆë¨¸ëŠ” í”„ë¡œë“€ì„œê°€ ì „ì†¡í•œ ìŠ¤í‚¤ë§ˆ IDì™€ ë©”ì‹œì§€ë¥¼ ì¡°í•©í•´ ì½ì„ ìˆ˜ ìˆë‹¤.
- ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì´ìš©í•˜ê¸° ìœ„í•´ì„œ ì§€ì›ë˜ëŠ” ë°ì´í„° í¬ë§·ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ë°, `ì—ì´ë¸Œë¡œ`ê°€ ê°€ì¥ ëŒ€í‘œì ì´ë‹¤.

<br/>

### 10.2.2 ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ ì—ì´ë¸Œë¡œ ì§€ì›
- `ì—ì´ë¸Œë¡œ`: ì‹œìŠ¤í…œ, í”„ë¡œê·¸ë˜ë° ì–¸ì–´, í”„ë¡œì„¸ì‹± í”„ë ˆì„ì›Œí¬ ì‚¬ì´ì—ì„œ ë°ì´í„° êµí™˜ì„ ë„ì™€ì£¼ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì§ë ¬í™” ì‹œìŠ¤í…œ
  - ë¹ ë¥¸ ë°”ì´ë„ˆë¦¬ ë°ì´í„° í¬ë§·ì„ ì§€ì›í•œë‹¤.
  - JSON í˜•íƒœì˜ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•  ìˆ˜ ìˆëŠ” ë§¤ìš° ê°„ê²°í•œ ë°ì´í„° í¬ë§·ì´ë‹¤.
 
- ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” ì—ì´ë¸Œë¡œ í¬ë§·ì„ ê°€ì¥ ë¨¼ì € ì§€ì›í–ˆê³ , ìµœê·¼ì—ëŠ” JSON, í”„ë¡œí† ì½œ ë²„í¼ í¬ë§·ë„ ì§€ì›í•œë‹¤.

<br/>

> **ìŠ¤í‚¤ë§ˆ ì˜ˆì œ íŒŒì¼ ìƒì„±**

```json
{
  "namespace": "student.avro", # ì´ë¦„ì„ ì‹ë³„í•˜ëŠ” ë¬¸ìì—´
  "type": "record", # ì—ì´ë¸Œë¡œëŠ” record, enums, arrays, maps ë“±ì„ ì§€ì›
  "doc": "Ths is an example of Avro", # ì‚¬ìš©ìë“¤ì—ê²Œ ì´ ìŠ¤í‚¤ë§ˆ ì •ì˜ì— ëŒ€í•œ ì„¤ëª… ì œê³µ
  "name": "Student", # ë ˆì½”ë“œì˜ ì´ë¦„ì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ìì—´ (í•„ìˆ«ê°’)
  "fields": [ # JSON ë°°ì—´ë¡œì„œ, í•„ë“œë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ëœ»í•¨
    # name: í•„ë“œ ì´ë¦„, type: ë°ì´í„° íƒ€ì… ì •ì˜, doc: ì£¼ì„
    {"name": "name", "type": "string", "doc": "Name of the student"},
    {"name": "class", "type": "int", "doc": "Class of the student"}
  ]
}
```
ğŸ”¼ ì—ì´ë¸Œë¡œë¥¼ í™œìš©í•œ í•™ìƒ ëª…ë‹¨ì— ëŒ€í•œ ìŠ¤í‚¤ë§ˆ ì •ì˜ íŒŒì¼
- ë°ì´í„° í•„ë“œë§ˆë‹¤ ë°ì´í„° íƒ€ì…ì„ ì •ì˜í•  ìˆ˜ ìˆë‹¤.
- docë¥¼ ì´ìš©í•´ ê° í•„ë“œì˜ ì˜ë¯¸ë¥¼ ì‚¬ìš©ìë“¤ì—ê²Œ ì •í™•í•˜ê²Œ ì „ë‹¬í•  ìˆ˜ ìˆë‹¤.

<br/>

### 10.2.3 ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì„¤ì¹˜
```
$ cd kafka2/
$ cd chapter2/ansible_playbook
$ ansible-playbook -i hosts kafka.yml
```
ğŸ”¼ ì¹´í”„ì¹´ í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜

<br/>

```
$ cd kakfa2/chapter2/ansible_playbook
$ ansible-playbook -i hosts site.yml
```
ğŸ”¼ ì£¼í‚¤í¼, ì¹´í”„ì¹´ ì¬ì„¤ì¹˜

<br/>

```
$ sudo wget http://packages.confluent.io/archive/6.1/confluent-community-6.1.0.tar.gz -0 /opt/confluent-community-6.1.0.tar.gz
$ sudo tar zxf /opt/confluent-community-6.1.0.tar.gz -C /usr/local
$ sudo ln -s /usr/local/confluent-6.1.0 /usr/local/confluent
```
ğŸ”¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ, ì••ì¶• í•´ì œ, ì‹¬ë³¼ë¦­ ë§í¬ ì„¤ì •

<br/>

```
vi /usr/local/confluent/etc/schema-registry/schema-registry.properties
```
ğŸ”¼ íŒŒì¼ ì—´ê¸°

<br/>

```
listeners=http://0.0.0.0:8081 # ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ì‚¬ìš©í•  TCP í¬íŠ¸ë¥¼ 8081 í¬íŠ¸ë¡œ ì§€ì •
kafkastore.bootstrap.servers=PLAINTEXT://peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092 # ìŠ¤í‚¤ë§ˆì˜ ë²„ì „ íˆìŠ¤í† ë¦¬ ë° ê´€ë ¨ ë°ì´í„°ë¥¼ ì €ì¥í•  ì¹´í”„ì¹´ ì£¼ì†Œë¥¼ ì…ë ¥
kafkastore.topic=_schemas # ìŠ¤í‚¤ë§ˆì˜ ë²„ì „ íˆìŠ¤í† ë¦¬ ë° ê´€ë ¨ ë°ì´í„° ì €ì¥ í† í”½ì˜ ì´ë¦„ì„ _schemasë¡œ ì§€ì •
schema.compatibility.level=full # ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± ë ˆë²¨ì„ fullë¡œ ì„¤ì •
```
ğŸ”¼ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì˜µì…˜ ì„¤ì •

<br/>

```
$ sudo vi /etc/systemd/system/schema-registry.service
```
ğŸ”¼ ì½”ë“œë¶€ë¥¼ ì…ë ¥í•˜ê¸° ìœ„í•œ íŒŒì¼ ì—´ê¸°

<br/>

```
[Unit]
Description=schema registry
After=network.target

[Service]
Type=simple
ExecStart=/usr/local/confluent/bin/schema-registry-start /usr/local/confluent/etc/schema-registry/schema-registry.properties
Restart=always

[Install]
WantedBy=multi-user.target
```
ğŸ”¼ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ system ì„¤ì •

<br/>

```
$ sudo systemctl daemon-reload
$ sudo systemctl start schema-registry
```
ğŸ”¼ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì‹¤í–‰

<br/>

|ì˜µì…˜|ì„¤ëª…|
|---|---|
|GET /schemas|í˜„ì¬ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡ëœ ì „ì²´ ìŠ¤í‚¤ë§ˆ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ|
|GET /schemas/ids/id|ìŠ¤í‚¤ë§ˆ IDë¡œ ì¡°íšŒ|
|GET /schemas/ids/id/versions|ìŠ¤í‚¤ë§ˆ IDì˜ ë²„ì „|
|GET /subjects|ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡ëœ subject ë¦¬ìŠ¤íŠ¸<br/>subjectëŠ” í† í”½ì´ë¦„-key, í† í”½ì´ë¦„-value í˜•íƒœë¡œ ì“°ì„|
|GET /subjects/ì„œë¸Œì íŠ¸ ì´ë¦„/versions|íŠ¹ì • ì„œë¸Œì íŠ¸ì˜ ë²„ì „ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ|
|GET /config|ì „ì—­ìœ¼ë¡œ ì„¤ì •ëœ í˜¸í™˜ì„± ë ˆë²¨ ì¡°íšŒ|
|GET /config/ì„œë¸Œì íŠ¸ ì´ë¦„|ì„œë¸Œì íŠ¸ì— ì„¤ì •ëœ í˜¸í™˜ì„± ì¡°íšŒ|
|DELETE /subjects/ì„œë¸Œì íŠ¸ ì´ë¦„|íŠ¹ì • ì„œë¸Œì íŠ¸ ì „ì²´ ì‚­ì œ|
|DELETE /subjects/ì„œë¸Œì íŠ¸ ì´ë¦„/versions/ë²„ì „|íŠ¹ì • ì„œë¸Œì íŠ¸ì—ì„œ íŠ¹ì • ë²„ì „ë§Œ ì‚­ì œ|

ğŸ”¼ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ API

<br/>

## 10.3 ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì‹¤ìŠµ
### 10.3.1 ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì™€ í´ë¼ì´ì–¸íŠ¸ ë™ì‘

<img alt="image" width="600" src="https://github.com/mash-up-kr/S3A/assets/55437339/6c48e4a4-5564-4f69-a4f9-3a7c44ba1463"/>

ğŸ”¼ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì™€ í´ë¼ì´ì–¸íŠ¸ ë™ì‘
1. ì—ì´ë¸Œë¡œ í”„ë¡œë“€ì„œëŠ” ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ ìŠ¤í‚¤ë§ˆê°€ ìœ íš¨í•œì§€ ì—¬ë¶€ë¥¼ í™•ì¸í•œë‹¤. (í™•ì¸ë˜ì§€ ì•Šìœ¼ë©´, ìŠ¤í‚¤ë§ˆ ë“±ë¡/ìºì‹œ)
2. ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” í˜„ ìŠ¤í‚¤ë§ˆê°€ ì €ì¥ì†Œì— ì €ì¥ëœ ìŠ¤í‚¤ë§ˆì™€ ë™ì¼í•œì§€, ì§„í™”í•œ ê²ƒì¸ì§€ í™•ì¸í•œë‹¤. (ë¬¸ì œ ì—†ìœ¼ë©´ í”„ë¡œë“€ì„œì—ê²Œ ê³ ìœ  ID ì‘ë‹µ)
3. í”„ë¡œë“€ì„œëŠ” ë°›ì€ ìŠ¤í‚¤ë§ˆ IDë¥¼ ì°¸ê³ í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì¹´í”„ì¹´ë¡œ ì „ì†¡í•œë‹¤.
4. ì—ì´ë¸Œë¡œ ì»¨ìŠˆë¨¸ëŠ” ìŠ¤í‚¤ë§ˆ IDë¡œ í† í”½ì— ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ ì½ëŠ”ë‹¤. (ì»¨ìŠˆë¨¸ì—ê²Œ ìŠ¤í‚¤ë§ˆ IDê°€ ì—†ë‹¤ë©´ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ê°€ì ¸ì˜´)

<br/>

### 10.3.2 íŒŒì´ì¬ì„ ì´ìš©í•œ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í™œìš©
```
$ sudo yum -y install python3
$ python3 -m venv venv10
$ source venv10/bin/activate
$ pip install confluent-kafka[avro]
```
ğŸ”¼ íŒŒì´ì¬ ì„¤ì¹˜, ê°€ìƒ í™˜ê²½(venv10) ìƒì„±, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

<br/>

```python
# http://github.com/confluentinc/confluent-kafka-pyton
# avro ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer

# ìŠ¤í‚¤ë§ˆ ì •ì˜
value_schema_str = """
{ "namespace": "stduent.avro",
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
  ]
}
"""
# ë°¸ë¥˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
value_schema = avro.loads(value_schema_str)
value = {"name": "Peter", "class": 1} # ì „ì†¡í•  ë©”ì‹œì§€


# ì „ì†¡ ê²°ê³¼ í™•ì¸
def delivery_report(err, msg):
  """ Called once for each message produced to indicate delivery result.
      Triggered by poll() or flush(). """
  if err is not None:
    print('Message delivery failed: {}'.format(err))
  else:
    print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition())

# AvroProducer ì†ì„± ì •ì˜
avroProducer = AvroProducer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'on_delivery': delivery_report,
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081'
  }, default_value_schema=value_schema)

# ë©”ì‹œì§€ ì „ì†¡
avroProducer.produce(topic='peter-avro2', value=value)
avroProducer.flush()
```
ğŸ”¼ ì—ì´ë¸Œë¡œ ë©”ì‹œì§€ ì „ì†¡ì„ ìœ„í•œ ê¸°ë³¸ íŒŒì´ì¬ ì—ì´ë¸Œë¡œ í”„ë¡œë“€ì„œ(python-avro-producer.py)

<br/>

```
$ python python-avro-producer.py

# ì¶œë ¥
Message delivered to peter-avro2 [0]
```
ğŸ”¼ í”„ë¡œë“€ì„œ ì‹¤í–‰

<br/>

```python
# http://github.com/confluentinc/confluent-kafka-pyton
# avro ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer
from confluent_kafka.avro.serializer import SerializerError

# ìŠ¤í‚¤ë§ˆ ì •ì˜
value_schema_str = """
{ "namespace": "stduent.avro",
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
  ]
}
"""
# ë°¸ë¥˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
value_schema = avro.loads(value_schema_str)

# AvroConsumer ì†ì„± ì •ì˜
c = AvroConsumer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'group.id': 'python-groupid01',
  'auto.offset.reset': 'earliest',
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081'}, reader_value_schema=value_schema)

# í† í”½ êµ¬ë…
c.subscribe(['peter-avro2'])

# ë©”ì‹œì§€ ì»¨ìŠ˜
while True:
  try:
    msg = c.poll(10)

  except SerializerError as e:
    print("Message deserialization failed for {}: {}".format(msg, e))
    break

  if msg is None:
    continue

  if msg.error():
    print("AvroConsumer error: {}".format(msg.error()))
    continue
    print(msg.value())

# ì¢…ë£Œ
c.close()
```
ğŸ”¼ ì—ì´ë¸Œë¡œ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ê¸°ë³¸ íŒŒì´ì¬ ì—ì´ë¸Œë¡œ ì»¨ìŠˆë¨¸(python-avro-consumer.py)
- peter-avro2 í† í”½ì„ ì»¨ìŠ˜í•œë‹¤.
- ì»¨ìŠˆë¨¸ ê·¸ë£¹ IDëŠ” python-groupid01ë¡œ ì²˜ìŒ ì˜¤í”„ì…‹ë¶€í„° ë©”ì‹œì§€ë¥¼ ì½ì–´ì˜¨ë‹¤.

<br/>

```
$ python python-avro-consumer.py

# ì¶œë ¥
{'name': 'Peter', 'class': 1}
```
ğŸ”¼ ì»¨ìŠˆë¨¸ ì‹¤í–‰

<br/>

```
$ curl http://peter-kafka03.foo.bar:8081/schemas | python -m json.tool
```
- ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ APIë¥¼ ì´ìš©í•´ ìŠ¤í‚¤ë§ˆê°€ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì˜ ê¸°ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<br/>

```python
# http://github.com/confluentinc/confluent-kafka-pyton
# avro ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer

# ìŠ¤í‚¤ë§ˆ ì •ì˜
value_schema_str = """
{ "namespace": "stduent.avro",
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "first_name", "type": ["null", "string"], "default": null, "doc": "First name of the student"},
    {"name": "last_name", "type": ["null", "string"], "default": null, "doc": "Last name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
  ]
}
"""
# ë°¸ë¥˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
value_schema = avro.loads(value_schema_str)
value = {"first_name": "Peter", "last_name": "Parker", "class": 1} # ì „ì†¡í•  ë©”ì‹œì§€

# ì „ì†¡ ê²°ê³¼ í™•ì¸
def delivery_report(err, msg):
  """ Called once for each message produced to indicate delivery result.
      Triggered by poll() or flush(). """
  if err is not None:
    print('Message delivery failed: {}'.format(err))
  else:
    print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition())

# AvroProducer ì†ì„± ì •ì˜
avroProducer = AvroProducer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'on_delivery': delivery_report,
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081'
  }, default_value_schema=value_schema)

# ë©”ì‹œì§€ ì „ì†¡
avroProducer.produce(topic='peter-avro2', value=value)
avroProducer.flush()
```
ğŸ”¼ ìŠ¤í‚¤ë§ˆë¥¼ ì¬ì •ì˜í•œ íŒŒì´ì¬ ì—ì´ë¸Œë¡œ í”„ë¡œë“€ì„œ(python-avro.producer2.py)
- ìŠ¤í‚¤ë§ˆì˜ name í•„ë“œë¥¼ ì‚­ì œí•˜ê³ , first_nameê³¼ last_nameì´ë¼ëŠ” 2ê°œì˜ í•„ë“œë¥¼ ì¶”ê°€í•œë‹¤.
- ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë¯€ë¡œ ë¹„êµì  ê°„ë‹¨í•˜ê²Œ ë³€ê²½ëœ ë‚´ìš©ì„ ì ìš©í•  ìˆ˜ ìˆë‹¤.

<br/>

```pyhon
# http://github.com/confluentinc/confluent-kafka-pyton
# avro ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer
from confluent_kafka.avro.serializer import SerializerError

# ìŠ¤í‚¤ë§ˆ ì •ì˜
value_schema_str = """
{ "namespace": "stduent.avro",
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "first_name", "type": ["null", "string"], "default": null, "doc": "First name of the student"},
    {"name": "last_name", "type": ["null", "string"], "default": null, "doc": "Last name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
  ]
}
"""

# ë°¸ë¥˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
value_schema = avro.loads(value_schema_str)

# AvroConsumer ì†ì„± ì •ì˜
c = AvroConsumer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'group.id': 'python-groupid02', # ìƒˆë¡œìš´ ì»¨ìŠˆë¨¸ ê·¸ë£¹ ì•„ì´ë”” ì ìš©
  'auto.offset.reset': 'earliest',
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081'}, reader_value_schema=value_schema)

# í† í”½ êµ¬ë…
c.subscribe(['peter-avro2'])

# ë©”ì‹œì§€ ì»¨ìŠ˜
while True:
  try:
    msg = c.poll(10)

  except SerializerError as e:
    print("Message deserialization failed for {}: {}".format(msg, e))
    break

  if msg is None:
    continue

  if msg.error():
    print("AvroConsumer error: {}".format(msg.error()))
    continue
    print(msg.value())

# ì¢…ë£Œ
c.close()
```
ğŸ”¼ ìŠ¤í‚¤ë§ˆë¥¼ ì¬ì •ì˜í•œ íŒŒì´ì¬ ì—ì´ë¸Œë¡œ ì»¨ìŠˆë¨¸(python-avro-consumer2.py)

<br/>

```
$ python python-avro-consumer2.py

# ì¶œë ¥
{'class': 1, 'first_name': None, 'last_name': None}
{'first_name': 'Peter', 'last_name': 'Parker', 'class': 1}
```
ğŸ”¼ ì»¨ìŠˆë¨¸ ì‹¤í–‰
- ì¶œë ¥ ê²°ê³¼ë¥¼ í†µí•´ ì´ 2ê°œì˜ ë©”ì‹œì§€ë¥¼ ì½ì—ˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.
  - ì²«ë²ˆì§¸: ìŠ¤í‚¤ë§ˆê°€ ì§„í™”í•˜ê¸° ì „ í”„ë¡œë“€ì„œê°€ ë³´ë‚¸ ë©”ì‹œì§€
  - ë‘ë²ˆì§¸: ìŠ¤í‚¤ë§ˆ ì§„í™” í›„ í”„ë¡œë“€ì„œê°€ ë³´ë‚¸ ë©”ì‹œì§€
 
- ì§„í™”ëœ ìŠ¤í‚¤ë§ˆë¥¼ ì»¨ìŠˆë¨¸ì— ì ìš©í–ˆìŒì—ë„ ì»¨ìŠˆë¨¸ëŠ” ìŠ¤í‚¤ë§ˆê°€ ë‹¤ë¥¸ ì²« ë²ˆì§¸ ë©”ì‹œì§€ë„ ì˜ ê°€ì ¸ì˜¨ë‹¤.

<br/>

```
$ curl http://peter-kafka03.foo.bar:8081/schemas | python -m json.tool

# ì¶œë ¥
...
  "version": 2,
  ...
  "schema": "{...\"first_name...\"last_name"...
...
```
ğŸ”¼ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ APIë¥¼ ì´ìš©í•œ ìŠ¤í‚¤ë§ˆ í™•ì¸
- ë²„ì „ì´ 2ë¡œ ë³€ê²½ëë‹¤.
- first_name, last_nameê³¼ ê°™ì´ ì§„í™”ëœ ìŠ¤í‚¤ë§ˆ ë‚´ìš©ì´ ë°˜ì˜ëë‹¤.

<br/>

```
curl http://peter-kafka03.foo.bar:8081/subjects/peter-avro2-value/versions | python -m json.tool

# ì¶œë ¥
[
  1,
  2
]
```
ğŸ”¼ ìŠ¤í‚¤ë§ˆ ë²„ì „ ë¦¬ìŠ¤íŠ¸ í™•ì¸
- 2ê°œì˜ ìŠ¤í‚¤ë§ˆ ë²„ì „ì´ ì¡´ì¬í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<br/>

## 10.4 ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í˜¸í™˜ì„±
### 10.4.1 BACKWARD í˜¸í™˜ì„±
- ì§„í™”ëœ ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•œ ì»¨ìŠˆë¨¸ê°€ **ì§„í™” ì „ì˜ ìŠ¤í‚¤ë§ˆê°€ ì ìš©ëœ í”„ë¡œë“€ì„œê°€ ë³´ë‚¸ ë©”ì‹œì§€**ë¥¼ ì½ì„ ìˆ˜ ìˆë„ë¡ í—ˆìš©í•œë‹¤.

<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/c5eb3efb-7079-4226-aee2-ac4977ce5f47"/>

ğŸ”¼ BACKWARD í˜¸í™˜ì„±
- ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë²„ì „ë³„ë¡œ ë²„ì „1, ë²„ì „2, ë²„ì „3ê¹Œì§€ì˜ ìŠ¤í‚¤ë§ˆê°€ ì €ì¥ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•œë‹¤.
- ì»¨ìŠˆë¨¸ëŠ” ìì‹ ê³¼ ë™ì¼í•œ ë²„ì „ì¸ ë²„ì „3 ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•˜ëŠ” í”„ë¡œë“€ì„œì˜ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.

<br/>

|í˜¸í™˜ì„± ë ˆë²¨|ì§€ì›ë²„ì „(ì»¨ìŠˆë¨¸ ê¸°ì¤€)|ë³€ê²½ í—ˆìš© í•­ëª©|ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ìˆœì„œ|
|---|---|---|---|
|BACKWARD|ìì‹ ê³¼ ë™ì¼í•œ ë²„ì „ê³¼ í•˜ë‚˜ ì•„ë˜ì˜ í•˜ìœ„ ë²„ì „|í•„ë“œ ì‚­ì œ, ê¸°ë³¸ ê°’ì´ ì§€ì •ëœ í•„ë“œ ì¶”ê°€|ì»¨ìŠˆë¨¸ -> í”„ë¡œë“€ì„œ|
|BACKWARD_TRANSITIVE|ìì‹ ê³¼ ë™ì¼í•œ ë²„ì „ì„ í¬í•¨í•œ ëª¨ë“  í•˜ìœ„ ë²„ì „|í•„ë“œ ì‚­ì œ, ê¸°ë³¸ ê°’ì´ ì§€ì •ëœ í•„ë“œ ì¶”ê°€|ì»¨ìŠˆë¨¸ -> í”„ë¡œë“€ì„œ|

ğŸ”¼ BACKWARD í˜¸í™˜ì„±

<br/>

### 10.4.2 FORWARD í˜¸í™˜ì„±
- **ì§„í™”ëœ ìŠ¤í‚¤ë§ˆê°€ ì ìš©ëœ í”„ë¡œë“€ì„œê°€ ë³´ë‚¸ ë©”ì‹œì§€**ë¥¼ ì „í™˜ ì „ì˜ ìŠ¤í‚¤ë§ˆê°€ ì ìš©ëœ ì»¨ìŠˆë¨¸ê°€ ì½ì„ ìˆ˜ ìˆê²Œ í•œë‹¤.

<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/d485aab1-6897-42be-a83a-cf30cacfb50d"/>

ğŸ”¼ FORWARD í˜¸í™˜ì„±
- ìµœì‹  ë²„ì „ì˜ ìŠ¤í‚¤ë§ˆ(ë²„ì „3)ë¥¼ ì´ìš©í•´ í”„ë¡œë“€ì„œê°€ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•  ë•Œ, ë™ì¼í•œ ë²„ì „(3)ì˜ ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•˜ëŠ” í”„ë¡œë“€ì„œëŠ” í”„ë¡œë“€ì„œê°€ ë³´ë‚¸ ë©”ì‹œì§€ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë‹¤.
- í•œë‹¨ê³„ ë‚®ì€ ë²„ì „(2) ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•˜ëŠ” ì»¨ìŠˆë¨¸ë„ ë²„ì „3 ìŠ¤í‚¤ë§ˆë¥¼ ì´ìš©í•˜ëŠ” í”„ë¡œë“€ì„œê°€ ë³´ë‚´ëŠ” ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.

<br/>

|í˜¸í™˜ì„± ë ˆë²¨|ì§€ì› ë²„ì „(ì»¨ìŠˆë¨¸ ê¸°ì¤€)|ë³€ê²½ í—ˆìš© í•­ëª©|ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ìˆœì„œ|
|---|---|---|---|
|FORWARD|ìì‹ ê³¼ ë™ì¼í•œ ë²„ì „ê³¼ í•˜ë‚˜ ìœ„ì˜ ìƒìœ„ ë²„ì „|í•„ë“œ ì¶”ê°€, ê¸°ë³¸ ê°’ì´ ì§€ì •ëœ í•„ë“œ ì‚­ì œ|í”„ë¡œë“€ì„œ -> ì»¨ìŠˆë¨¸|
|FORWARD_TRANSITIVE|ìì‹ ê³¼ ë™ì¼í•œ ë²„ì „ì„ í¬í•¨í•œ ëª¨ë“  ìƒìœ„ ë²„ì „|í•„ë“œ ì¶”ê°€, ê¸°ë³¸ ê°’ì´ ì§€ì •ëœ í•„ë“œ ì‚­ì œ|í”„ë¡œë“€ì„œ -> ì»¨ìŠˆë¨¸|

ğŸ”¼ FORWARD í˜¸í™˜ì„± ìš”ì•½ ì •ë¦¬

<br/>

### 10.4.3 FULL í˜¸í™˜ì„±
- BACKWARDì™€ FORWARD í˜¸í™˜ì„± ëª¨ë‘ë¥¼ ì§€ì›í•œë‹¤.
- ê°€ì¥ ìµœê·¼ 2ê°œì˜ ë²„ì „ ìŠ¤í‚¤ë§ˆë¥¼ ì§€ì›í•œë‹¤.

<br/>

|í˜¸í™˜ì„± ë ˆë²¨|ì§€ì› ë²„ì „(ì»¨ìŠˆë¨¸ ê¸°ì¤€)|ë³€ê²½ í—ˆìš© í•­ëª©|ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ìˆœì„œ|
|---|---|---|---|
|FULL|ìì‹ ê³¼ ë™ì¼í•œ ë²„ì „ê³¼ í•˜ë‚˜ ìœ„ ë˜ëŠ” í•˜ë‚˜ ì•„ë˜ ë²„ì „|í•„ë“œ ì¶”ê°€, ê¸°ë³¸ ê°’ì´ ì§€ì •ëœ í•„ë“œ ì‚­ì œ|ìˆœì„œ ìƒê´€ì—†ìŒ|
|FULL_TRANSITIVE|ìì‹ ê³¼ ë™ì¼í•œ ë²„ì „ì„ í¬í•¨í•œ ëª¨ë“  ìƒìœ„ ë²„ì „ê³¼ í•˜ìœ„ ë²„ì „|í•„ë“œ ì¶”ê°€, ê¸°ë³¸ ê°’ì´ ì§€ì •ëœ í•„ë“œ ì‚­ì œ|ìˆœì„œ ìƒê´€ì—†ìŒ|

ğŸ”¼ FULL í˜¸í™˜ì„± ìš”ì•½ ì •ë¦¬

<br/>

### 10.4.4 ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í˜¸í™˜ì„± ì‹¤ìŠµ

```
listeners=http://0.0.0.0:8081
kafkastore.bootstrap.servers=PLAINTEXT://peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092
kafkastore.topic=_schemas
schema.compatibility.level=backward # í˜¸í™˜ì„± ë ˆë²¨ ì„¤ì •
```
ğŸ”¼ ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì„¤ì • (/usr/local/confluent/etc/schema-registry/schema-registry.properties)
- API ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ í˜¸í™˜ì„± ë ˆë²¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
  ```
  $ sudo systemctl restart schema-registry
  $ curl -X GET http://peter-kafka03.foo.bar:8081/config
  ```

<br/>

```
{ "namespace": "stduent.avro",
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
  ]
}
```
ğŸ”¼ ì´ë¦„ê³¼ ë°˜ í•„ë“œë¥¼ ì •ì˜í•œ BACKWARD í˜¸í™˜ì„± V1 ìŠ¤í‚¤ë§ˆ
- ì‹¤ìŠµìš© í† í”½ êµ¬ì„±ì´ í•„ìš”í•˜ë¯€ë¡œ, ì•„ë˜ì™€ ê°™ì€ ì†ì„±ì˜ í† í”½ì„ ìƒì„±í•œë‹¤.
  - ì´ë¦„: peter-avro3
  - íŒŒí‹°ì…˜: 1
  - ë¦¬í”Œë¦¬ì¼€ì´ì…˜ íŒ©í„°: 3
 
- í† í”½ ìƒì„± í›„, ì •ì˜í•œ ìŠ¤í‚¤ë§ˆë¥¼ ì´ìš©í•´ íŒŒì´ì¬ ì—ì´ë¸Œë¡œ í”„ë¡œë“€ì„œ ì‘ì„± í›„ ì‹¤í–‰í•œë‹¤.

<br/>

```
# http://github.com/confluentinc/confluent-kafka-pyton
# avro ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer

# ìŠ¤í‚¤ë§ˆ ì •ì˜
value_schema_str = """
{ "namespace": "stduent.avro", # BACKWARD í˜¸í™˜ì„± ì‹¤ìŠµ V1 ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•œ ì—ì´ë¸Œë¡œ í”„ë¡œë“€ì„œ
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
  ]
}
"""

# ë°¸ë¥˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
value_schema = avro.loads(value_schema_str)
value = {"name": "Peter", "class": 1} # ì „ì†¡í•  ë©”ì‹œì§€

# ì „ì†¡ ê²°ê³¼ í™•ì¸
def delivery_report(err, msg):
  """ Called once for each message produced to indicate delivery result.
      Triggered by poll() or flush(). """
  if err is not None:
    print('Message delivery failed: {}'.format(err))
  else:
    print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition())

# AvroProducer ì†ì„± ì •ì˜
avroProducer = AvroProducer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'on_delivery': delivery_report,
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081'
  }, default_value_schema=value_schema)

# ë©”ì‹œì§€ ì „ì†¡
avroProducer.produce(topic='peter-avro3', value=value) # peter-avro3 í† í”½ìœ¼ë¡œ ë©”ì‹œì§€ ë°œì†¡
avroProducer.flush()
```
ğŸ”¼ BACKWARD í˜¸í™˜ì„± V1 ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•œ ì—ì´ë¸Œë¡œ í”„ë¡œë“€ì„œ(python-avro-producer_v1.py)

<br/>

```
# http://github.com/confluentinc/confluent-kafka-pyton
# avro ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer
from confluent_kafka.avro.serializer import SerializerError

# ìŠ¤í‚¤ë§ˆ ì •ì˜
value_schema_str = """
{ "namespace": "stduent.avro", # BACKWARD í˜¸í™˜ì„± ì‹¤ìŠµ V1 ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•œ ì—ì´ë¸Œë¡œ ì»¨ìŠˆë¨¸
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
  ]
}
"""

# ë°¸ë¥˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
value_schema = avro.loads(value_schema_str)

# AvroConsumer ì†ì„± ì •ì˜
c = AvroConsumer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'group.id': 'python-groupid01', # ì»¨ìŠˆë¨¸ ê·¸ë£¹ ì•„ì´ë””
  'auto.offset.reset': 'earliest',
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081'}, reader_value_schema=value_schema)

# í† í”½ êµ¬ë…
c.subscribe(['peter-avro3']) # peter-avro3 í† í”½ì„ ì»¨ìŠ˜

# ë©”ì‹œì§€ ì»¨ìŠ˜
while True:
  try:
    msg = c.poll(10)

  except SerializerError as e:
    print("Message deserialization failed for {}: {}".format(msg, e))
    break

  if msg is None:
    continue

  if msg.error():
    print("AvroConsumer error: {}".format(msg.error()))
    continue
    print(msg.value())

# ì¢…ë£Œ
c.close()
```
ğŸ”¼ BACKWARD í˜¸í™˜ì„± V1 ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•œ ì—ì´ë¸Œë¡œ ì»¨ìŠˆë¨¸(python-avro-consumer_v1.py)
- ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•´ë³´ë©´ í”„ë¡œë“€ì„œì—ì„œ ì „ì†¡í•œ ë©”ì‹œì§€ë¥¼ ì½ì–´ì˜¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<br/>

```
{ "namespace": "stduent.avro",
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
    {"name": "age", "type": "int", "default": 1, "doc": "Age of the student"}
  ]
}
```
ğŸ”¼ ì´ë¦„ê³¼ ë°˜ í•„ë“œì— ë‚˜ì´ í•„ë“œë¥¼ ì¶”ê°€í•œ BACKWARD í˜¸í™˜ì„± V2 ìŠ¤í‚¤ë§ˆ
- age í•„ë“œê°€ ì¶”ê°€ëë‹¤.(ê¸°ë³¸ê°’ì€ 1)
- í•´ë‹¹ V2 ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡œë“€ì„œì™€ ì»¨ìŠˆë¨¸ í´ë¼ì´ì–¸íŠ¸ë“¤ë„ ìƒìœ„ ë²„ì „ì˜ ìŠ¤í‚¤ë§ˆê°€ ì ìš©ë˜ì–´ì•¼ í•œë‹¤.

<br/>

```
# http://github.com/confluentinc/confluent-kafka-pyton
# avro ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer

# ìŠ¤í‚¤ë§ˆ ì •ì˜
value_schema_str = """
{ "namespace": "stduent.avro", # BACKWARD í˜¸í™˜ì„± ì‹¤ìŠµ V1 ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•œ ì—ì´ë¸Œë¡œ í”„ë¡œë“€ì„œ
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"},
    {"name": "age", "type": "int", "default": 1, "doc": "Age of the student"} # ë‚˜ì´ í•„ë“œë¥¼ ì¶”ê°€í•œ BACKWARD í˜¸í™˜ì„± V2 ìŠ¤í‚¤ë§ˆ ì ìš©
  ]
}
"""

# ë°¸ë¥˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
value_schema = avro.loads(value_schema_str)
value = {"name": "Peter", "class": 1, "age": 2} # ì „ì†¡í•  ë©”ì‹œì§€

# ì „ì†¡ ê²°ê³¼ í™•ì¸
def delivery_report(err, msg):
  """ Called once for each message produced to indicate delivery result.
      Triggered by poll() or flush(). """
  if err is not None:
    print('Message delivery failed: {}'.format(err))
  else:
    print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition())

# AvroProducer ì†ì„± ì •ì˜
avroProducer = AvroProducer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'on_delivery': delivery_report,
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081'
  }, default_value_schema=value_schema)

# ë©”ì‹œì§€ ì „ì†¡
avroProducer.produce(topic='peter-avro3', value=value) # peter-avro3 í† í”½ìœ¼ë¡œ ë©”ì‹œì§€ ë°œì†¡
avroProducer.flush()
```
ğŸ”¼ BACKWARD í˜¸í™˜ì„± V2 ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•œ ì—ì´ë¸Œë¡œ í”„ë¡œë“€ì„œ(python-avro-producer_v2.py)
- í”„ë¡œë“€ì„œë¥¼ ê°€ìƒí™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ë©´ í•´ë‹¹ ë©”ì‹œì§€ê°€ ì „ì†¡ëœë‹¤.
- ë©”ì‹œì§€ ì „ì†¡ í›„ ì»¨ìŠˆë¨¸ì˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ë³´ë©´ V2 ìŠ¤í‚¤ë§ˆê°€ ì ìš©ë˜ì§€ ì•Šì•˜ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.(ì»¨ìŠˆë¨¸ëŠ” ì•„ì§ V1ì´ê¸° ë•Œë¬¸)

<br/>

```
# http://github.com/confluentinc/confluent-kafka-pyton
# avro ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer
from confluent_kafka.avro.serializer import SerializerError

# ìŠ¤í‚¤ë§ˆ ì •ì˜
value_schema_str = """
{ "namespace": "stduent.avro", # BACKWARD í˜¸í™˜ì„± ì‹¤ìŠµ V1 ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•œ ì—ì´ë¸Œë¡œ ì»¨ìŠˆë¨¸
  "type": "record",
  "doc": "This is an example of Avro.",
  "name": "Student",
  "fields": [
    {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
    {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"},
    {"name": "age", "type": "int", "default": 1, "doc": "Age of the student"} # ë‚˜ì´ í•„ë“œë¥¼ ì¶”ê°€í•œ BACKWARD í˜¸í™˜ì„± V2 ìŠ¤í‚¤ë§ˆ ì ìš©
  ]
}
"""

# ë°¸ë¥˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
value_schema = avro.loads(value_schema_str)

# AvroConsumer ì†ì„± ì •ì˜
c = AvroConsumer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'group.id': 'python-groupid01', # ì»¨ìŠˆë¨¸ ê·¸ë£¹ ì•„ì´ë””
  'auto.offset.reset': 'earliest',
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081'}, reader_value_schema=value_schema)

# í† í”½ êµ¬ë…
c.subscribe(['peter-avro3']) # peter-avro3 í† í”½ì„ ì»¨ìŠ˜

# ë©”ì‹œì§€ ì»¨ìŠ˜
while True:
  try:
    msg = c.poll(10)

  except SerializerError as e:
    print("Message deserialization failed for {}: {}".format(msg, e))
    break

  if msg is None:
    continue

  if msg.error():
    print("AvroConsumer error: {}".format(msg.error()))
    continue
    print(msg.value())

# ì¢…ë£Œ
c.close()
```
ğŸ”¼ BACKWARD í˜¸í™˜ì„± V2 ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•œ ì—ì´ë¸Œë¡œ ì»¨ìŠˆë¨¸(python-avro-consumer_v2.py)
- í”„ë¡œë“€ì„œ(V2)ë¥¼ ì‹¤í–‰í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ë‹¤ì‹œ ì „ì†¡í•˜ê³ , ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰ì‹œì¼œë³´ë©´ age í•„ë“œë„ ì¶”ê°€ëœ ë©”ì‹œì§€ë¥¼ ì½ì–´ì˜´ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
- ê²°êµ­ ì™„ë²½í•œ ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œëŠ” í˜¸í™˜ì„± ë ˆë²¨ì—ì„œ ê°€ì´ë“œí•˜ëŠ” ìˆœì„œë¥¼ ì˜ ë”°ë¼ì•¼ í•œë‹¤. (BACKWARDì—ì„œëŠ” consumer -> producer)

<br/>

## 10.5 ì •ë¦¬
- í•œë²ˆ ìŠ¤í‚¤ë§ˆë¥¼ ê¹”ë”í•˜ê²Œ ì •ì˜í•´ë†“ëŠ”ë‹¤ë©´, ì´í›„ ìŠ¤í‚¤ë§ˆ ë³€ê²½ì— ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•  ìˆ˜ ìˆë‹¤.
- ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ í™œìš©í•¨ìœ¼ë¡œì¨ ë°ì´í„° ê´€ë¦¬ì ì¸ ì¸¡ë©´ì„ ê°•í™”í•œë‹¤ë©´ ì§€ê¸ˆë³´ë‹¤ ë”ìš± íš¨ìœ¨ì ì¸ ë°ì´í„° ì²˜ë¦¬ì™€ ìš´ì˜ì´ ê°€ëŠ¥í•  ê²ƒì´ë‹¤.
