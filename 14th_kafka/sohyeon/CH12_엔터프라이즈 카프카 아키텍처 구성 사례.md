# 12장 엔터프라이즈 카프카 아키텍처 구성 사례

## 12.1 엔터프라이즈용 카프카 아키텍처의 개요

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/d5cb2d14-8920-44d2-9e87-7760de57b257"/>

🔼 엔터프라이즈 환경에서 미러 메이커 사용 예제
- 카프카 간의 데이터 리플리케이션에는 주로 **미러 메이커**를 사용한다.
- (1) 업스트림 카프카와 다운스트림 카프카 사이에 리플리케이션이 필요한 경우이다.
- (2) 여러 데이터 센터마다 카프카가 존재하고 중앙에 있는 카프카로 데이터를 모으기 위해 리플리케이션을 사용하는 경우이다.

<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/c2cb52a3-611d-43ce-9d86-81a9c3f3ccf7"/>

🔼 엔터프라이즈 환경에서 카프카와 가장 많이 연동되어 쓰이는 애플리케이션들
- 중앙의 카프카 클러스터로 합쳐진 데이터는 실시간 처리와 분석을 위해 별도의 애플리케이션에 적재된다.
- 카프카와 연동해 많이 사용되는 예로 **장기 계획 배치**가 가능한 하둡, **실시간 검색**이 가능한 엘라스틱서치, AWS의 대표적인 **스토리지**인 S3, **빅데이터**를 실시간으로 읽고 쓸 수 있는 HBase 등이 있다.
- 각 애플리케이션마다 각기 다른 컨슈머가 필요하다. (for 카프카의 데이터를 적재하기 위한 토픽 컨슘)

<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/b1ba5afe-d99e-491a-8c5b-cd0fd5b9496c"/>

🔼 카프카 엔터프라이즈 환경 구성도
- 카프카 클러스터는 총 2개(업스트림 클러스터, 다운스트림 클러스터)로, **다운스트림 카프카는 업스트림 카프카를 미러링**한다.
- 카프카 간의 미러링을 위해 카프카 커넥트 기반의 **미러 메이커 2.0**이 동작한다.
- 양쪽의 카프카 클러스터는 효율적인 스키마 관리를 위해 **스키마 레지스트리**를 사용한다.
- 데이터의 흐름은 다음과 같다.
  - `프로듀서-1`이 업스트림 카프카로 메시지를 전송한다. (스키마 레지스트리 사용)
  - `컨슈머-1`은 업스트림 카프카로부터 메시지를 읽는다. (`프로듀서-1`과 동일한 스키마 레지스트리 이용)
  - `프로듀서-1`을 이용해 업스트림 카프카로 전송하는 메시지들은 미러 메이커 2.0을 통해 다운 스트림 카프카로 미러링된다.
  - 실시간 분석을 위해 `컨슈머-2`가 다운스트림 카프카로부터 메시지를 읽은 뒤 `엘라스틱서치`로 메시지를 전송한다.
    - 엘라스틱서치에서 제공하는 REST API 또는 `키바나`를 통해 관리자는 데이터를 확인할 수 있다.
   
- 관리 또는 모니터링 측면에서 업스트림 카프카와 다운스트림 카프카는 `CMAK`를 이용해 카프카의 토픽들을 관리할 수 있다.
  - 양쪽 카프카 클러스터들에서 발생하는 메트릭들이 `프로메테우스`에 저장된다.
  - 관리자는 `그라파나`를 통해 그래프 형태로 모니터링할 수 있다.
 
<br/>

## 12.2 엔터프라이즈용 카프카의 환경 구성

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/49151e89-c9dc-4c8a-ac20-b4fabf3534f5"/>

🔼 서버별로 실행되는 애플리케이션
- 필요한 애플리케이션은 다음과 같다.
  - 주키퍼
  - 카프카 클러스터 2개
  - 카프카 커넥트
  - 스키마 레지스트리
  - CMAK
  - 엘라스틱서치
  - 키바나
  - 모니터링 도구
 
- **주키퍼**는 1개의 앙상블만 구성하고, 지노드를 분리해 카프카 클러스터 2개가 하나의 주키퍼 앙상블을 바라보도록 구성한다.
- **카프카 커넥트**는 다운스트림 카프카와 같이 위치한다.
  - 미러링 동작은 프로듀서 + 컨슈머 동작으로 이뤄진다.
  - 업스트림과 함께 위치할 경우, 프로듀서가 메시지 전송 시 네트워크 장애 상황에 노출될 때 일부 메시지가 유실될 가능성이 높다.
  - 다운스트림과 함께 위치할 경우, 다운스트림으로 전송하는 프로듀서는 로컬 네트워크 환경에서 동작하므로 네트워크 관련 장애는 거의 발생하지 않을 것이다.
  - **프로듀서는 컨슈머보다 네트워크 장애에 더욱 민감하므로 다운스트림 카프카와 가까운 위치에 배치하는 것이 중요**하다.
 
<br/>

```
cd kafka2/
cd chapter12/ansible_playbook
ansible-playbook -i hosts site.yml
ansible-playbook -i hosts exporter.yml
ansible-playbook -i hosts monitoring.yml
```
- 전체 애플리케이션을 설치한다.
- peter-ansible01 서버에 접속하여 깃허브 예제 파일을 다운로드해둔 경로로 이동 후 명령어를 실행한다.
  - `site.yml`: 주키퍼, 카프카, 스키마 레지스트리, 카프카 커넥트 등
  - `exporter.yml`: JMX, 노드, 카프카 익스포터 등
  - `monitoring.yml`: 그라파나, 프로메테우스 등
 
<br/>

## 12.3 엔터프라이즈용 카프카의 운영 실습

### 12.3.1 CMAK를 이용한 토픽 생성

1. CMAK와 카프카 클러스터 연동
   - `http://peter-kafka01.foo.bar:9000` 주소로 접근
   - Cluster 드롭다운 메뉴를 클릭해 Add Cluster 선택
   - 클러스터의 상세 정보 입력
     - `Cluster Name`: kafka-1(업스트림 카프카)
     - `Cluster Zookeeper Hosts`: peter-zk01.foo.bar:2181,peter-zk02.foo.bar:2181,peter-zk03.foo.bar:2181/kafka3
     - `Enable JMX Polling`: 활성화
    
   - SAVE 버튼을 눌러 설정 마무리
  
2. 같은 방식으로 카프카 클러스터 `kafka-2` 추가(연동)
   - `Cluster Name`: kafka-2(다운스트림 카프카)
   - `Cluster Zookeeper Hosts`: peter-zk01.foo.bar:2181,peter-zk02.foo.bar:2181,peter-zk03.foo.bar:2181/kafka4
  
3. kafka-1 클러스터에 토픽(실습용) 생성
   - Cluster > List > kafka-1을 클릭해 `kafka-1`의 메인 메뉴로 이동
   - 상단 메뉴 중 Topic을 클릭해 드롭다운 메뉴 중 Create를 선택해서 토픽 생성 메뉴로 진입 (CMAK의 토픽 생성 메뉴)
   - 토픽의 상세 옵션 설정
     - `Topic`: peter-avro01-kafka1
     - `Partitions`: 1
     - `Replication Factor`: 3
    
   - Create 클릭
  
<br/>

### 12.3.2 카프카 커넥트 설정

```
$ curl --header "Content-Type: application/json" --header
"Accept: application/json" --request PUT --data '{
"name": "peter-mirrormaker2",
"connector.class": "org.apache.kafka.connect.mirror.MirrorSourceConnector", # 커넥터에서 사용하는 클래스 정의
"tasks.max": "1",

# 소스 클러스터(src)와 타깃 클러스트(dst)의 에일리어스(별칭) 지정
"source.cluster.alias": "src",
"target.cluster.alias": "dst",

# 소스 클러스터와 타깃 클러스터의 부트스트랩 서버 리스트 설정
"source.cluster.bootstrap.servers": "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092",
"target.cluster.bootstrap.servers": "peter-zk01.foo.bar:9092,peter-zk02.foo.bar:9092,peter-zk03.foo.bar:9092",

"replication.factor": "3", # 타깃 클러스터의 토픽을 생성할 때 리플리케이션 팩터 수(3) 지정
"topics": "peter-avro01-kafka1"
}' http://peter-zk01.foo.bar:8083/connectors/peter-mirrormaker2/config
```
- curl 명령어를 이용한 미러 소스 커넥터 등록
- `src.peter-avro01-kafka01` 토픽이 미러 메이커를 이용해 업스트림 카프카의 `peter-avro01-kafka1` 토픽을 미머링한다.

<br/>

### 12.3.3 모니터링 환경 구성
- `http://peter-kafka01.foo.bar:3000`: 그라파나 접근
  - 아이디: admin
  - 비밀번호: admin
 
- 프로메테우스 연동 (그라파나 대시보드 생성 절차와 동일)
  - `Name`: Prometheus
  - 'URL': http://peter-kafka01.foo.bar:9090
 
- 대시보드 생성
  - Kafka Metrics 대시보드(kafka_metrics.json)
  - Kafka Exporter Overview 대시보드(7589)
  - Node Exporter 대시보드(1860)
 
<br/>

### 12.3.4 메시지 전송과 확인

```
$ git clone https://github.com/onlybooks/kafka2
$ sudo yum -y install python3
$ python3 -m venv venv12
$ source venv12/bin/activate
$ pip install confluent-kafka[avro]
$ pip install names
$ pip install elasticsearch
```
- 라이브러리(confluent-kafka[avro], names, elasticsearch) 설치

<br/>

```python
# avro, names, random 관련 모듈 임포트
from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer
import names
import random

# 스키마 정의
value_schema_str = """
{"namespace": "studnet.avro",
 "type": "record",
 "doc": "This is an example of Avro.",
 "name": "Student",
 "fields": [
   {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
   {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
 ]
}
"""

# 밸류 스키마 코드
value_schema = avro.loads(value_schema_str)

# 전송 결과 확인
def delivery_report(errm msg):
  """Called once for each message produced to indicate delivery result.
     Triggered by poll() or flush()."""
  if err is not None:
    print('Message delivery failed: {}'.format(err))
  else:
    print('Message dlivered to {} [{}]'.format(msg.topic(), msg.offset()))

# AvroProducer 속성 정의
avroProducer = AvroProducer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'on_delivery': delivery_report,
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081`
  }, default_value_schema=value_schema)

# 메시지 전송
for x in range(100):
  value = {"name": names.get_first_name(), "class": random.randint(1,5)} # 전송할 메시지
  avroProducer.produce(topic='peter-avro01-kafka1', value=value)

avroProducer.flush()
```
🔼 파이썬 코드로 작성한 업스트림 카프카로 메시지를 전송하는 파이썬 프로듀서 예제(producer-1_kafka-1_v1.py)
- 스키마를 정의한다.
  - 학생의 이름(name): 문자형(string)
  - 학생이 속한 반(class): 정수형(int)
 
- 학생 이름과 반을 랜덤으로 생성해 총 100개의 데이터를 업스트림 카프카의 peter-avro01-kafka1 토픽으로 전송한다.

<br/>

```
$ python kafka2/chapter12/python/producer-1_kafka-1_v1.py
```
- 프로듀서 파일 실행
- 전송한 메시지는 가장 먼저 업스트림 카프카의 `peter-avro01-kafka1`로 저장된다.
- 업스트림의 `peter-avro01-kafka1` 토픽의 메시지는 **미러링**을 통해 다운스트림 카프카의 `src.peter-avro01-kafka1` 토픽에도 동일하게 저장된다.

<br/>

```python
# avro 관련 모듈 임포트
from confluent_kafka import avro
from confluent_kafka.avro import AvroConsumer
from confluent_kafka.avro.serializer import SerializeError

# 스키마 정의
value_schema_str = """
{"namespace": "studnet.avro",
 "type": "record",
 "doc": "This is an example of Avro.",
 "name": "Student",
 "fields": [
   {"name": "name", "type": ["null", "string"], "default": null, "doc": "Name of the student"},
   {"name": "class", "type": "int", "default": 1, "doc": "Class of the student"}
 ]
}
"""

# 밸류 스키마 코드
value_schema = avro.loads(value_schema_str)

# AvroConsumer 속성 정의
c = AvroConsumer({
  'bootstrap.servers': 'peter-kafka01.foo.bar,peter-kafka02.foo.bar,peter-kafka03.foo.bar',
  'group.id': 'python-groupid01',
  'auto.offset.reset': 'earliest',
  'schema.registry.url': 'http://peter-kafka03.foo.bar:8081`
  }, reader_value_schema=value_schema)

# 토픽 구독
c.subscribe(['peter-avro01-kafka1'])

# 메시지 컨슘
while True:
  try:
    msg = c.poll(10)

  except SerializerError as e:
    print("Message deserialization failed for {}: {}".format(msg, e))
    break

  if msg is None:
    continue

  if msg.error():
    print("AvroConsumer error: {}".format(msg.error()))
    continue

  print(msg.value())

# 종료
c.close()
```
🔼 파이썬 코드로 작성한 업스트림 카프카에서 메시지를 컨슘하는 에이브로 컨슈머(consumer-1_kafka-1_v1.py)
- 프로듀서가 보낸 메시지가 잘 전송됐는지 확인한다.

<br/>

```
$ python kafka2/chapter12/python/consumer-1_kafka-1_v1.py
```
- 컨슈머 파일 실행
- 학생으로 정의한 스키마를 이용해 프로듀서가 메시지를 전송했고, 컨슈머 역시 오류 없이 메시지를 읽을 수 있다는 사실을 확인할 수 있다.

<br/>

```
$ curl -X GET 'http://peter-kafka02.foo.bar:9200/_cat/indices?v'
```
- 엘라스틱서치에서 제공하는 REST API를 이용해 **인덱스**를 체크한다.
  - `도큐먼트`: 데이터 단위
  - `인덱스`: 도큐먼트를 모아놓은 것
 
- 출력 내용은 엘라스틱서치로 미러링된 메시지들의 전송이 이루어지기 전이므로 엘라스틱서치의 메뉴 항목과 일부 카바나 관련 인덱스들만 출력된다.

<br/>

```python

```
🔼 파이썬으로 작성한 다운스트림 카프카에서 메시지를 읽어 엘라스틱서치로 전송하는 컨슈머(consumer_kafka-2_producer_es_v1.py)
